models <- list('GPT2', 'lstm_gulordava')
options(warn=1)
models <- list('GPT2', 'lstm_gulordava')
datasets <- list('NP-S', 'NP-Z', 'N-V-V', 'N-V-N')
library(plyr)
for (model in models) {
for (dataset in datasets) {
data <- read.csv(paste0('results/regression/', dataset, '-', model, '_Pdata.csv'))
sink(paste0('results/regression/', dataset, '-', model, '_results.txt'))
data$n_cues <- as.factor(data$n_cues)
data$stimulus_id <- as.factor(data$n_cues)
pre_post <- glm(P~pre + post,data=data,family=binomial(link = 'logit'))
n_cues <- glm(P~n_cues,data=data,family=binomial(link = 'logit'))
pre <- glm(P~pre,data=data,family=binomial(link = 'logit'))
post <- glm(P~post,data=data,family=binomial(link = 'logit'))
cue <- glm(P~cue,data=data,family=binomial(link = 'logit'))
cat('P~pre + post\tBIC ', BIC(pre_post), '\n')
cat('P~n_cues\tBIC ', BIC(n_cues), '\n')
cat('P~pre\tBIC ', BIC(pre), '\n')
cat('P~post\tBIC ', BIC(post), '\n')
cat('P~cue\tBIC ', BIC(cue), '\n')
print(summary(pre_post))
print(summary(n_cues))
print(summary(pre))
print(summary(post))
print(summary(cue))
sink()
}
}
warnings()
